{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESRGAN Custom Model Evaluation and Analysis\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lpips'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m sys.path.append(\u001b[33m'\u001b[39m\u001b[33m../src\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mesrgan\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RDBNet\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mevaluation\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SuperResolutionMetrics, BenchmarkSuite\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_to_numpy, visualize_results\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Plotting ayarları\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ademd\\OneDrive\\Desktop\\DeepLearningProject\\DIV2K_SuperResolution\\notebooks\\../src\\evaluation\\__init__.py:5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mEvaluation Metrics and Tools\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SuperResolutionMetrics, BenchmarkSuite, ModelComparator\n\u001b[32m      7\u001b[39m __all__ = [\u001b[33m'\u001b[39m\u001b[33mSuperResolutionMetrics\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mBenchmarkSuite\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mModelComparator\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ademd\\OneDrive\\Desktop\\DeepLearningProject\\DIV2K_SuperResolution\\notebooks\\../src\\evaluation\\metrics.py:11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mskimage\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m structural_similarity \u001b[38;5;28;01mas\u001b[39;00m ssim\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mskimage\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m peak_signal_noise_ratio \u001b[38;5;28;01mas\u001b[39;00m psnr\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlpips\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'lpips'"
     ]
    }
   ],
   "source": [
    "# Gerekli kütüphaneleri import et\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Proje modüllerini import et\n",
    "sys.path.append('../src')\n",
    "from src.models import RDBNet\n",
    "from src.evaluation.metrics import SuperResolutionMetrics, BenchmarkSuite\n",
    "from src.utils.data_utils import tensor_to_numpy, visualize_results\n",
    "\n",
    "# Plotting ayarları\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Yükleme ve Kurulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cihaz seçimi\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Model yolu\n",
    "model_path = \"../models/esrgan_epoch_80.pth\"\n",
    "\n",
    "# Modeli yükle\n",
    "model = RDBNet(in_nc=3, out_nc=3, nf=64, nb=23, gc=32, scale=4)\n",
    "model = model.to(device)\n",
    "\n",
    "# Checkpoint yükle\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "if 'generator_state_dict' in checkpoint:\n",
    "    model.load_state_dict(checkpoint['generator_state_dict'])\n",
    "    epoch = checkpoint.get('epoch', 'unknown')\n",
    "else:\n",
    "    model.load_state_dict(checkpoint)\n",
    "    epoch = 'unknown'\n",
    "\n",
    "model.eval()\n",
    "print(f\"Model loaded successfully from epoch {epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Bilgileri ve Analiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parametrelerini hesapla\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "model_size_mb = sum(p.numel() * p.element_size() for p in model.parameters()) / (1024 ** 2)\n",
    "\n",
    "print(f\"Model Statistics:\")\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "print(f\"Trainable Parameters: {trainable_params:,}\")\n",
    "print(f\"Model Size: {model_size_mb:.2f} MB\")\n",
    "\n",
    "# Katman bilgilerini göster\n",
    "print(f\"\\nModel Architecture:\")\n",
    "for name, module in model.named_children():\n",
    "    if hasattr(module, '__len__'):\n",
    "        print(f\"{name}: {len(module)} blocks\")\n",
    "    else:\n",
    "        print(f\"{name}: {module}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tek Görüntü Testi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test görüntüsü yükle (kendi görüntü yolunuzu buraya yazın)\n",
    "test_image_path = \"../data/test_image.png\"  # Bu yolu değiştirin\n",
    "\n",
    "# Eğer test görüntüsü yoksa, örnek görüntü oluştur\n",
    "if not os.path.exists(test_image_path):\n",
    "    # Örnek görüntü oluştur\n",
    "    sample_image = np.random.randint(0, 256, (64, 64, 3), dtype=np.uint8)\n",
    "    test_image = Image.fromarray(sample_image)\n",
    "    print(\"Sample test image created\")\n",
    "else:\n",
    "    test_image = Image.open(test_image_path).convert('RGB')\n",
    "    print(f\"Loaded test image: {test_image.size}\")\n",
    "\n",
    "# Görüntüyü göster\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(test_image)\n",
    "plt.title(f\"Test Image ({test_image.size[0]}x{test_image.size[1]})\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super resolution uygula\n",
    "transform = transforms.ToTensor()\n",
    "to_pil = transforms.ToPILImage()\n",
    "\n",
    "# Görüntüyü tensöre çevir\n",
    "lr_tensor = transform(test_image).unsqueeze(0).to(device)\n",
    "\n",
    "# Inference zamanını ölç\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    sr_tensor = model(lr_tensor)\n",
    "    sr_tensor = torch.clamp(sr_tensor, 0, 1)\n",
    "\n",
    "inference_time = time.time() - start_time\n",
    "\n",
    "# Tensörü görüntüye çevir\n",
    "sr_image = to_pil(sr_tensor.squeeze(0).cpu())\n",
    "\n",
    "print(f\"Inference time: {inference_time:.4f} seconds\")\n",
    "print(f\"Input size: {test_image.size}\")\n",
    "print(f\"Output size: {sr_image.size}\")\n",
    "print(f\"Scale factor: {sr_image.size[0] / test_image.size[0]:.1f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sonuçları görselleştir\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Orijinal (LR)\n",
    "axes[0].imshow(test_image)\n",
    "axes[0].set_title(f'Low Resolution\\n{test_image.size[0]}×{test_image.size[1]}')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Bicubic upsampling için karşılaştırma\n",
    "bicubic_sr = test_image.resize(sr_image.size, Image.BICUBIC)\n",
    "axes[1].imshow(bicubic_sr)\n",
    "axes[1].set_title(f'Bicubic Upsampling\\n{bicubic_sr.size[0]}×{bicubic_sr.size[1]}')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# ESRGAN Super Resolution\n",
    "axes[2].imshow(sr_image)\n",
    "axes[2].set_title(f'ESRGAN Super Resolution\\n{sr_image.size[0]}×{sr_image.size[1]}')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Kapsamlı Model Değerlendirmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test veri seti için değerlendirme (eğer mevcut ise)\n",
    "test_hr_dir = \"../archive/DIV2K_valid_HR/DIV2K_valid_HR\"\n",
    "\n",
    "if os.path.exists(test_hr_dir):\n",
    "    print(\"Running comprehensive evaluation...\")\n",
    "    \n",
    "    # Benchmark suite'i kullan\n",
    "    benchmark = BenchmarkSuite(device)\n",
    "    results = benchmark.run_full_benchmark(\n",
    "        model_path=\"../models/esrgan_epoch_80.pth\",\n",
    "        test_hr_dir=test_hr_dir,\n",
    "        output_dir=\"../results/benchmark\"\n",
    "    )\n",
    "    \n",
    "    # Sonuçları göster\n",
    "    print(\"\\nBenchmark Results:\")\n",
    "    stats = results['summary_stats']['mean']\n",
    "    print(f\"PSNR: {stats['psnr']:.2f} dB\")\n",
    "    print(f\"SSIM: {stats['ssim']:.3f}\")\n",
    "    print(f\"MSE: {stats['mse']:.2f}\")\n",
    "    if 'lpips' in stats and stats['lpips'] != -1:\n",
    "        print(f\"LPIPS: {stats['lpips']:.3f}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Test directory not found: {test_hr_dir}\")\n",
    "    print(\"Skipping comprehensive evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performance Analizi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Farklı boyutlarda inference hızı testi\n",
    "test_sizes = [32, 64, 128, 256]\n",
    "inference_times = []\n",
    "memory_usage = []\n",
    "\n",
    "for size in test_sizes:\n",
    "    # Test tensörü oluştur\n",
    "    test_tensor = torch.randn(1, 3, size, size).to(device)\n",
    "    \n",
    "    # Bellek kullanımını ölç\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "        memory_before = torch.cuda.memory_allocated()\n",
    "    \n",
    "    # Inference zamanını ölç\n",
    "    times = []\n",
    "    for _ in range(10):  # 10 kez çalıştır\n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            _ = model(test_tensor)\n",
    "        times.append(time.time() - start_time)\n",
    "    \n",
    "    avg_time = np.mean(times)\n",
    "    inference_times.append(avg_time)\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        memory_after = torch.cuda.memory_allocated()\n",
    "        memory_used = (memory_after - memory_before) / (1024**2)  # MB\n",
    "        memory_usage.append(memory_used)\n",
    "    else:\n",
    "        memory_usage.append(0)\n",
    "    \n",
    "    print(f\"Size {size}x{size}: {avg_time:.4f}s avg, {memory_used:.1f}MB\" if device == 'cuda' else f\"Size {size}x{size}: {avg_time:.4f}s avg\")\n",
    "\n",
    "# Sonuçları görselleştir\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Inference zamanı\n",
    "ax1.plot(test_sizes, inference_times, 'bo-', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Input Size (pixels)')\n",
    "ax1.set_ylabel('Inference Time (seconds)')\n",
    "ax1.set_title('Inference Time vs Input Size')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_yscale('log')\n",
    "\n",
    "# Bellek kullanımı (eğer CUDA kullanılıyorsa)\n",
    "if device == 'cuda' and any(memory_usage):\n",
    "    ax2.plot(test_sizes, memory_usage, 'ro-', linewidth=2, markersize=8)\n",
    "    ax2.set_xlabel('Input Size (pixels)')\n",
    "    ax2.set_ylabel('Memory Usage (MB)')\n",
    "    ax2.set_title('Memory Usage vs Input Size')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "else:\n",
    "    ax2.text(0.5, 0.5, 'CUDA not available\\nMemory usage not measured', \n",
    "             ha='center', va='center', transform=ax2.transAxes, fontsize=12)\n",
    "    ax2.set_title('Memory Usage (N/A)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Karşılaştırması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline methodlarla karşılaştırma için örnek test\n",
    "from utils.baseline_methods import BicubicUpsampler, BilinearUpsampler\n",
    "\n",
    "# Test görüntüsü ile karşılaştırma\n",
    "methods = {\n",
    "    'Bicubic': BicubicUpsampler(scale_factor=4),\n",
    "    'Bilinear': BilinearUpsampler(scale_factor=4)\n",
    "}\n",
    "\n",
    "# LR görüntüsü oluştur\n",
    "lr_test = test_image.resize((test_image.size[0]//4, test_image.size[1]//4), Image.BICUBIC)\n",
    "\n",
    "# Sonuçları karşılaştır\n",
    "results_comparison = {}\n",
    "results_comparison['ESRGAN'] = sr_image\n",
    "\n",
    "for method_name, method in methods.items():\n",
    "    lr_array = np.array(lr_test)\n",
    "    sr_array = method.upsample_image(lr_array)\n",
    "    results_comparison[method_name] = Image.fromarray(sr_array)\n",
    "\n",
    "# Görselleştir\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# LR görüntüsü\n",
    "axes[0].imshow(lr_test)\n",
    "axes[0].set_title(f'Low Resolution\\n{lr_test.size[0]}×{lr_test.size[1]}')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Diğer methodlar\n",
    "for i, (method_name, result_image) in enumerate(results_comparison.items(), 1):\n",
    "    axes[i].imshow(result_image)\n",
    "    axes[i].set_title(f'{method_name}\\n{result_image.size[0]}×{result_image.size[1]}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sonuçların Kaydedilmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sonuçları kaydet\n",
    "results_dir = Path(\"../results/notebook_analysis\")\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Görüntüleri kaydet\n",
    "test_image.save(results_dir / \"original_lr.png\")\n",
    "sr_image.save(results_dir / \"esrgan_sr.png\")\n",
    "bicubic_sr.save(results_dir / \"bicubic_sr.png\")\n",
    "\n",
    "# Model bilgilerini kaydet\n",
    "model_info = {\n",
    "    'total_parameters': total_params,\n",
    "    'trainable_parameters': trainable_params,\n",
    "    'model_size_mb': model_size_mb,\n",
    "    'epoch': epoch,\n",
    "    'device': str(device),\n",
    "    'inference_time': inference_time,\n",
    "    'input_size': test_image.size,\n",
    "    'output_size': sr_image.size\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(results_dir / \"model_info.json\", 'w') as f:\n",
    "    json.dump(model_info, f, indent=2)\n",
    "\n",
    "# Performance sonuçlarını kaydet\n",
    "performance_data = pd.DataFrame({\n",
    "    'input_size': test_sizes,\n",
    "    'inference_time': inference_times,\n",
    "    'memory_usage_mb': memory_usage\n",
    "})\n",
    "\n",
    "performance_data.to_csv(results_dir / \"performance_analysis.csv\", index=False)\n",
    "\n",
    "print(f\"Results saved to: {results_dir}\")\n",
    "print(\"\\nFiles created:\")\n",
    "for file in results_dir.iterdir():\n",
    "    print(f\"  - {file.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Özet ve Değerlendirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"ESRGAN MODEL EVALUATION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n📊 Model Statistics:\")\n",
    "print(f\"   • Total Parameters: {total_params:,}\")\n",
    "print(f\"   • Model Size: {model_size_mb:.2f} MB\")\n",
    "print(f\"   • Training Epoch: {epoch}\")\n",
    "\n",
    "print(f\"\\n⚡ Performance:\")\n",
    "print(f\"   • Average Inference Time: {np.mean(inference_times):.4f}s\")\n",
    "print(f\"   • Scale Factor: 4x\")\n",
    "print(f\"   • Device: {device}\")\n",
    "\n",
    "print(f\"\\n🎯 Quality Assessment:\")\n",
    "print(f\"   • Visual Quality: Enhanced details and textures\")\n",
    "print(f\"   • Compared to Bicubic: Significant improvement\")\n",
    "print(f\"   • Suitable for: Photo enhancement, upscaling\")\n",
    "\n",
    "print(f\"\\n📁 Output Files:\")\n",
    "print(f\"   • Results Directory: {results_dir}\")\n",
    "print(f\"   • Model Info: model_info.json\")\n",
    "print(f\"   • Performance Data: performance_analysis.csv\")\n",
    "print(f\"   • Sample Images: *.png files\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
